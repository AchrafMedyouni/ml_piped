[Data Leakage]: Feature selection and under-sampling are performed on the entire dataset before cross-validation, leading to data leakage because information from the test folds influences the training folds in each cross-validation split.
[Bias from Undersampling]: Undersampling can introduce bias if the minority class is not representative of the overall population, or if the undersampling is too aggressive, leading to loss of important information.
[Suboptimal Feature Selection]: Performing feature selection before cross-validation means that the feature selection is not performed independently for each fold, which can lead to overfitting and an inaccurate estimate of model performance on unseen data.
